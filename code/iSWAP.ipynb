{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep every_ith control. Increase this if you want to decrease the number of controls being considered.\n",
    "every_ith = 12\n",
    "import os\n",
    "import dill\n",
    "import numpy as np\n",
    "mypath = 'controls_106'\n",
    "_file = 'pickled_controls106.pkl'\n",
    "filename = os.path.join(mypath, _file)\n",
    "pca = dill.load(open(filename, 'rb'))\n",
    "\n",
    "def bangbang(index, x, d1, d2, d3, d4):\n",
    "    if x:\n",
    "        xory = 0\n",
    "    else:\n",
    "        xory = 1\n",
    "    dt = pca.dt\n",
    "    num_steps = pca.controlset[0].shape[0]\n",
    "    control_hamiltonians = pca.control_hamiltonians\n",
    "    controls = np.zeros((num_steps, int(len(pca.control_hamiltonians))))\n",
    "    controls[index, xory] = (1 / dt * np.pi / 2) * d1\n",
    "    controls[-(index+1), xory] = 1 / dt * np.pi / 2 * d2\n",
    "    controls[index, 2+xory] = 1 / dt * np.pi / 2 * d3\n",
    "    controls[-(index+1), 2+xory] = 1 / dt * np.pi / 2 * d4\n",
    "    return controls\n",
    "\n",
    "controls = []\n",
    "import itertools\n",
    "for directions in list(itertools.product([-1, 1], repeat=4)):\n",
    "    for x in (True, False):\n",
    "        for i in range(int(pca.controlset[0].shape[0]/2)):\n",
    "            if i % every_ith != 0:\n",
    "                continue\n",
    "            controls.append(bangbang(i, x, *directions))\n",
    "pca.controlset = controls\n",
    "pca.num_controls = len(pca.controlset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convex import all_derivs\n",
    "derivs = all_derivs(pca.controlset, pca.target_operator, pca.control_hamiltonians, pca.ambient_hamiltonian, pca.dt, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pauli_channel_approximation import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It looks like excluding controls with even a small amount (< 1%) of support can impact the performance of the RBC. Therefore we should be sure to set this hyperparameter correctly, to penalize for nonsparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with convex problem 0 out of 64\n",
      "Done with convex problem 10 out of 64\n",
      "Done with convex problem 20 out of 64\n",
      "Done with convex problem 30 out of 64\n",
      "Done with convex problem 40 out of 64\n",
      "Done with convex problem 50 out of 64\n",
      "Done with convex problem 60 out of 64\n"
     ]
    }
   ],
   "source": [
    "from convex import optimal_weights\n",
    "pca.weights_0 = optimal_weights(derivs[:1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with convex problem 0 out of 64\n",
      "Done with convex problem 10 out of 64\n",
      "Done with convex problem 20 out of 64\n",
      "Done with convex problem 30 out of 64\n",
      "Done with convex problem 40 out of 64\n",
      "Done with convex problem 50 out of 64\n",
      "Done with convex problem 60 out of 64\n"
     ]
    }
   ],
   "source": [
    "from convex import optimal_weights\n",
    "pca.weights = optimal_weights(derivs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def hist_and_support(weights, num=10):\n",
    "    plt.hist(weights)\n",
    "    np.argmax(weights)\n",
    "    top_idx = np.argsort(np.array(weights).T)[0][-num:]\n",
    "    top_values = [weights[i] for i in top_idx]\n",
    "    print(f\"SUPPORT:{np.sum(top_values)}\")\n",
    "    print(f\"NUM CONTROLS: {num}\")\n",
    "    return top_idx, np.sum(top_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_weights = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUPPORT:1.0000000901172452\n",
      "NUM CONTROLS: 20\n"
     ]
    }
   ],
   "source": [
    "idx0, supp = hist_and_support(pca.weights_0, num_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca0 = dill.load(open(filename, 'rb'))\n",
    "subweights = pca.weights_0[idx0]\n",
    "pca0.controlset = [pca0.controlset[i] for i in idx0]\n",
    "pca0.probs = list(np.array(subweights.T/sum(subweights)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03953771833416804"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "order = 0\n",
    "# Zeroth order optimized weights\n",
    "scipy.linalg.norm(np.matrix(np.array([d.flatten() for d in derivs[order]])[idx0]).T.dot(pca0.probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.339356728455202"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "order = 1\n",
    "# Zeroth order optimized weights\n",
    "scipy.linalg.norm(np.matrix(np.array([d.flatten() for d in derivs[order]])[idx0]).T.dot(pca0.probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUPPORT:0.9999999800698227\n",
      "NUM CONTROLS: 20\n"
     ]
    }
   ],
   "source": [
    "idx1, supp = hist_and_support(pca.weights, num_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 = dill.load(open(filename, 'rb'))\n",
    "subweights = pca.weights[idx1]\n",
    "pca1.controlset = [pca1.controlset[i] for i in idx1]\n",
    "pca1.probs = list(np.array(subweights.T/sum(subweights)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.464581046062231e-09"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "order = 0\n",
    "# Zeroth order optimized weights\n",
    "scipy.linalg.norm(np.matrix(np.array([d.flatten() for d in derivs[order]])[idx1]).T.dot(pca1.probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10398328481099234"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "order = 1\n",
    "# Zeroth order optimized weights\n",
    "scipy.linalg.norm(np.matrix(np.array([d.flatten() for d in derivs[order]])[idx1]).T.dot(pca1.probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weighted controls\n",
    "import dill\n",
    "dill.dump(pca0, open('0_' + _file, 'wb'))\n",
    "\n",
    "import dill\n",
    "dill.dump(pca1, open('1_' + _file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weighted controls\n",
    "import dill\n",
    "import os\n",
    "mypath = 'controls_106'\n",
    "_file = 'pickled_controls106.pkl'\n",
    "filename = os.path.join(mypath, _file)\n",
    "pca = dill.load(open(filename, 'rb'))\n",
    "\n",
    "pca0 = dill.load(open('0_' + _file, 'rb'))\n",
    "pca1 = dill.load(open('1_' + _file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pauli_channel_approximation import control_unitaries, error_unitary, off_diagonal_projection, adjoint\n",
    "import sys\n",
    "import itertools\n",
    "from itertools import product\n",
    "from copy import deepcopy\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "\n",
    "from diamond import diamond_norm, jamiolkowski\n",
    "\n",
    "def superoperator(unitary):\n",
    "\n",
    "    return np.kron(unitary.conj(), unitary)\n",
    "\n",
    "def choi_form(unitary):\n",
    "    return np.matrix(jamiolkowski(superoperator(unitary)))\n",
    "\n",
    "def diamond_distance(unitary_a,unitary_b):\n",
    "    unitary_a = np.matrix(unitary_a)\n",
    "    unitary_b = np.matrix(unitary_b)\n",
    "    arg = (choi_form(unitary_a) - choi_form(unitary_b))/2\n",
    "    rtn = diamond_norm(arg)\n",
    "    return rtn\n",
    "\n",
    "def compute_diamond_norm(data):\n",
    "    controlset, ambient_hamiltonian0, combo, dt, control_hamiltonians, target_operator, probs = data\n",
    "    print(\"DOING COMBO {}\".format(combo))\n",
    "    sys.stdout.flush()\n",
    "    fidelities = []\n",
    "    projs = []\n",
    "    sops = []\n",
    "    controlset_unitaries = []\n",
    "    d_norms = []\n",
    "\n",
    "    for controls in controlset:\n",
    "        newcontrols = deepcopy(controls)\n",
    "        ambient_hamiltonian = [deepcopy(ah).astype(\"complex\") for ah in ambient_hamiltonian0]\n",
    "        for cnum, value in enumerate(combo):\n",
    "            cnum -= len(ambient_hamiltonian0)\n",
    "            if cnum >= 0:\n",
    "                newcontrols[:, cnum] = newcontrols[:, cnum] * (1 + value)\n",
    "            if cnum < 0:\n",
    "                if cnum == -1:\n",
    "                    ambient_hamiltonian[cnum] *= 1 + float(value)\n",
    "                else:\n",
    "                    ambient_hamiltonian[cnum] *= float(value)\n",
    "        step_unitaries = control_unitaries(ambient_hamiltonian,\n",
    "                                           control_hamiltonians, newcontrols,\n",
    "                                           dt)\n",
    "        unitary = reduce(lambda a, b: a.dot(b), step_unitaries)\n",
    "        sop = error_unitary(unitary, target_operator)\n",
    "        sops.append(sop)\n",
    "        d_norms.append(diamond_distance(sop, np.eye(sop.shape[0])))\n",
    "    avg_sop = reduce(lambda a, b: a + b, [prob * sops[i] for i, prob in enumerate(probs)])\n",
    "    d_norms.append(diamond_distance(avg_sop, np.eye(avg_sop.shape[0])))\n",
    "    return d_norms\n",
    "\n",
    "def generate_indices(num_points, order_desired):\n",
    "    num_indices = len(order_desired)\n",
    "    tuples = product(range(num_points), repeat=num_indices)\n",
    "    indices = [sum([num_points**(num_indices - 1 - order_desired[i]) * t[i] \n",
    "                    for i in range(num_indices)]) for t in tuples]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOING COMBO [-0.001000000000000001, 0, 0, 0, 0, 0, 0]\n",
      "<class 'numpy.matrixlib.defmatrix.matrix'>\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "all_results = []\n",
    "for j, pca in enumerate((pca0, pca1)):\n",
    "    base = np.logspace(-4.7, np.log(pca.detunings[0][0])/np.log(10), 1)\n",
    "    controls = np.concatenate([np.sort(-base),np.array([0]), base])\n",
    "    combinations0 = [[det, 0, 0, 0, 0, 0, 0] for det in controls]\n",
    "    combinations1 = [[0, det, 0, 0, 0, 0, 0] for det in controls]\n",
    "    combinations2 = [[0, 0, det, 0, 0, 0, 0] for det in controls]\n",
    "    combinations3 = [[0, 0, 0, det, det, 0, 0] for det in controls]\n",
    "    combinations4 = [[0, 0, 0, 0, 0, det, det] for det in controls]\n",
    "\n",
    "    d_norms00 = []\n",
    "    for i in range(len(combinations0)):\n",
    "        combo = combinations0[i]\n",
    "        lst = [pca.controlset, pca.ambient_hamiltonian, combo, pca.dt,\n",
    "                pca.control_hamiltonians, pca.target_operator, pca.probs]\n",
    "        d_norms00.append(compute_diamond_norm(lst))\n",
    "        dill.dump(d_norms00, open('d_norms00_{}_{}'.format(i, j), 'wb'))\n",
    "\n",
    "    d_norms01 = []\n",
    "    for i in range(len(combinations1)):\n",
    "        combo = combinations1[i]\n",
    "        lst = [pca.controlset, pca.ambient_hamiltonian, combo, pca.dt,\n",
    "                pca.control_hamiltonians, pca.target_operator, pca.probs]\n",
    "        d_norms01.append(compute_diamond_norm(lst))\n",
    "        dill.dump(d_norms01, open('d_norms01_{}_{}'.format(i, j), 'wb'))\n",
    "\n",
    "    d_norms02 = []\n",
    "    for i in range(len(combinations2)):\n",
    "        combo = combinations2[i]\n",
    "        lst = [pca.controlset, pca.ambient_hamiltonian, combo, pca.dt,\n",
    "                pca.control_hamiltonians, pca.target_operator, pca.probs]\n",
    "        d_norms02.append(compute_diamond_norm(lst))\n",
    "        dill.dump(d_norms02, open('d_norms02_{}_{}'.format(i, j), 'wb'))\n",
    "\n",
    "    d_norms03 = []\n",
    "    for i in range(len(combinations3)):\n",
    "        combo = combinations3[i]\n",
    "        lst = [pca.controlset, pca.ambient_hamiltonian, combo, pca.dt,\n",
    "                pca.control_hamiltonians, pca.target_operator, pca.probs]\n",
    "        d_norms03.append(compute_diamond_norm(lst))\n",
    "        dill.dump(d_norms03, open('d_norms03_{}_{}'.format(i, j), 'wb'))\n",
    "\n",
    "    d_norms04 = []\n",
    "    for i in range(len(combinations4)):\n",
    "        combo = combinations4[i]\n",
    "        lst = [pca.controlset, pca.ambient_hamiltonian, combo, pca.dt,\n",
    "                pca.control_hamiltonians, pca.target_operator, pca.probs]\n",
    "        d_norms04.append(compute_diamond_norm(lst))\n",
    "        dill.dump(d_norms04, open('d_norms04_{}_{}'.format(i, j), 'wb'))\n",
    "        \n",
    "    all_results.append(d_norms00, d_norms01, d_norms02, d_norms03, d_norms04)\n",
    "dill.dump(all_results, open('all_results', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
